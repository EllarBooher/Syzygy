#version 460
#extension GL_EXT_buffer_reference2 : require
#extension GL_ARB_shading_language_include : require
#extension GL_EXT_nonuniform_qualifier : require

// Deferred shading pass consuming a GBuffer plus array of shadowmaps.
// Supports directional and spot lights.
// Portions are based on results in https://renderwonk.com/publications/s2010-shading-course/

#include "../gbuffer/gbuffer.glinl"
#include "../gbuffer/pbr.glinl"
#include "../types/camera.glsl"
#include "../types/lights.glsl"

layout(local_size_x = 16, local_size_y = 16) in;
layout(rgba16, set = 0, binding = 0) uniform image2D image;

SZG_DECLARE_GBUFFER_SET(1)
#include "../gbuffer/gbufferFunctions.glinl"
#include "../gbuffer/pbrFunctions.glinl"

layout(set = 2, binding = 0) uniform sampler shadowMapSampler;
layout(set = 3, binding = 0) uniform texture2D shadowMaps[];

layout(buffer_reference, std430) readonly buffer CameraBuffer
{
    Camera cameras[];
};

layout(buffer_reference, std430) readonly buffer LightDirectionalBuffer
{
    LightDirectional lights[];
};

layout(buffer_reference, std430) readonly buffer LightSpotBuffer
{
    LightSpot lights[];
};

layout(push_constant) uniform PushConstant
{
    CameraBuffer cameraBuffer;
    uint padding0;
    uint padding1;

    LightDirectionalBuffer directionalLights;
    LightSpotBuffer spotLights;

    uint directionalLightCount;
    uint spotLightCount;
    uint directionalLightSkipCount;
    uint cameraIndex;

    vec2 gbufferOffset;
    vec2 gbufferExtent;
} pushConstant;

// clang-format off
const mat4 TO_TEX_COORD_MAT = mat4(
	0.5, 0.0, 0.0, 0.0,
	0.0, 0.5, 0.0, 0.0,
	0.0, 0.0, 1.0, 0.0,
	0.5, 0.5, 0.0, 1.0
);
// clang-format on

struct ShadowFrame
{
    vec4 coord;
    float dx;
    float dy;
};

ShadowFrame computeShadowFrame(mat4 lightProjView, vec3 position, vec3 normal)
{
    const mat4 shadowMatrix = TO_TEX_COORD_MAT * lightProjView;
    vec4 shadowCoord = shadowMatrix * vec4(position, 1.0);
    shadowCoord /= shadowCoord.w;

    const vec4 projectedNormal = shadowMatrix * vec4(normal, 0.0);

    // The smaller the normal gets in shadowmap space, the further out we should sample
    const float dx = sqrt(1.0 - clamp(projectedNormal.x * projectedNormal.x, 0.0, 1.0));
    const float dy = sqrt(1.0 - clamp(projectedNormal.y * projectedNormal.y, 0.0, 1.0));

    return ShadowFrame(shadowCoord, dx, dy);
}

float sampleShadowMap(const ShadowFrame shadow, const uint index)
{
    float fragmentDepth = shadow.coord.z;

    const ivec2 shadowmapDimensions = textureSize(sampler2D(shadowMaps[index], shadowMapSampler), 0);

    const float dx = 1.5 * shadow.dx / float(shadowmapDimensions.x);
    const float dy = 1.5 * shadow.dy / float(shadowmapDimensions.y);

    float summedDistance = 0.0;

    const int SAMPLE_RANGE = 2;
    const int SAMPLE_COUNT = (2 * SAMPLE_RANGE + 1) * (2 * SAMPLE_RANGE + 1);

    for (int y = -SAMPLE_RANGE; y <= SAMPLE_RANGE; y++)
    {
        for (int x = -SAMPLE_RANGE; x <= SAMPLE_RANGE; x++)
        {
            vec2 offsetShadowCoord = shadow.coord.st + vec2(x * dx, y * dy);

            const float occluderDepth =
                texture(nonuniformEXT(sampler2D(shadowMaps[index], shadowMapSampler)), offsetShadowCoord).r;

            // Reverse-Z
            if (occluderDepth > 0.0 && occluderDepth > fragmentDepth)
            {
                summedDistance += 1.0;
            }
        }
    }

    return 1.0 - summedDistance / SAMPLE_COUNT;
}

struct IncomingLight
{
    vec3 lightDirectionUnit;
    vec3 lightSpectralFactor;
};

IncomingLight computeIncomingLight(const LightDirectional light, const ShadowFrame shadow, const uint shadowMapIndex)
{
    const vec3 lightDirectionUnit = normalize(-light.forward.xyz);
    const vec3 lightSpectralFactor = light.color.rgb * light.strength * sampleShadowMap(shadow, shadowMapIndex);

    return IncomingLight(lightDirectionUnit, lightSpectralFactor);
}

IncomingLight computeIncomingLight(const LightSpot light,
                                   const vec3 worldPosition,
                                   const ShadowFrame shadow,
                                   const uint shadowMapIndex)
{
    const vec3 lightDirectionUnit = normalize(-light.forward.xyz);

    const float lightNormalizedDistance = distance(light.position.xyz, worldPosition) / light.falloffDistance;
    const float lightFalloff = light.falloffFactor * lightNormalizedDistance * lightNormalizedDistance;

    // Quadratic falloff from center of light to edge, using the shadowmap as the bounds of the light
    const float distanceUV = clamp(distance(shadow.coord.st, vec2(0.5, 0.5)) / 0.5, 0.0, 1.0);
    const float edgeSoftening = 1.0 - distanceUV * distanceUV;

    const vec3 lightSpectralFactor =
        light.color.rgb * light.strength / lightFalloff * edgeSoftening * sampleShadowMap(shadow, shadowMapIndex);

    return IncomingLight(lightDirectionUnit, lightSpectralFactor);
}

vec3 computeLightContribution(const IncomingLight light, const PBRTexel material, const vec3 viewDirection)
{
    // Our model uses a microfacet specular BRDF layered with a diffuse BRDF
    // The assumption is that all diffuse light is scattered from whatever is not reflected as a specular highlight

    const vec3 lightDirection = light.lightDirectionUnit;

    const vec3 diffuseContribution = diffuseBRDF(material, lightDirection);
    const vec3 specularContribution = specularBRDF(material, lightDirection, viewDirection);

    const vec3 fresnel = computeFresnel(material, lightDirection, viewDirection);

    // Lerping preserves the energy conservation of our BRDFs
    return material.occlusion * mix(diffuseContribution, specularContribution, fresnel) * light.lightSpectralFactor
         * clamp(dot(material.normal, lightDirection), 0.0, 1.0);
}

void main()
{
    const vec2 size = imageSize(image);
    const ivec2 texelCoord = ivec2(gl_GlobalInvocationID.xy + pushConstant.gbufferOffset);
    if (texelCoord.x >= size.x || texelCoord.y >= size.y)
    {
        return;
    }

    // The uv needs to be offset to avoid floating point errors on texel boundaries
    const vec2 offset = vec2(0.5, 0.5);
    const vec2 gbufferUV = (vec2(texelCoord) + offset) / pushConstant.gbufferExtent;

    const GBufferTexel gbufferTexel = sampleGBuffer(gbufferUV);

    // No transparent geometry for now, less than 1.0 alpha indicates background texels
    if (gbufferTexel.diffuseColor.a < 1.0)
    {
        return;
    }

    const PBRTexel material = convertPBRProperties(gbufferTexel);

    const Camera camera = pushConstant.cameraBuffer.cameras[pushConstant.cameraIndex];
    const vec3 viewDirection = normalize(camera.position.xyz - material.position.xyz);

    vec3 lightContribution = vec3(0.0);

    // We assume shadow maps are laid out in the following order across all lights
    uint shadowMapIndex = pushConstant.directionalLightSkipCount;

    for (int i = int(pushConstant.directionalLightSkipCount); i < pushConstant.directionalLightCount; i++)
    {
        const LightDirectional light = pushConstant.directionalLights.lights[i];
        const ShadowFrame shadow =
            computeShadowFrame(light.projection * light.view, material.position, material.normal);
        const IncomingLight incomingLight = computeIncomingLight(light, shadow, shadowMapIndex);
        lightContribution += computeLightContribution(incomingLight, material, viewDirection);

        shadowMapIndex += 1;
    }

    for (int i = 0; i < pushConstant.spotLightCount; i++)
    {
        const LightSpot light = pushConstant.spotLights.lights[i];
        const ShadowFrame shadow =
            computeShadowFrame(light.projection * light.view, material.position, material.normal);
        const IncomingLight incomingLight = computeIncomingLight(light, material.position, shadow, shadowMapIndex);
        lightContribution += computeLightContribution(incomingLight, material, viewDirection);

        shadowMapIndex += 1;
    }

    imageStore(image, texelCoord, vec4(lightContribution, 1.0));
}